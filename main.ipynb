{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import joblib\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets: go_emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/debarshichanda/goemotions/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('dataset/goemotions_1.csv')\n",
    "df2 = pd.read_csv('dataset/goemotions_2.csv')\n",
    "df3 = pd.read_csv('dataset/goemotions_3.csv')\n",
    "\n",
    "df = pd.concat([df1, df2, df3])\n",
    "df = df.reset_index()\n",
    "df['index'] = [i for i in range(df.shape[0])]\n",
    "df = df.set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GPU(for Mac)\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "# use GPU(for CUDA)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "def preprocess_with_bert(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "    outputs = model(**inputs)\n",
    "    # use the output of the [CLS] token as the sentence embedding\n",
    "    sentence_embedding = outputs.last_hidden_state[:, 0, :].squeeze().detach().cpu().numpy()\n",
    "    return sentence_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use BERT to embed each text in the df['text'] column\n",
    "# This step may take a long time, depending on your hardware performance\n",
    "# I strongly recommend you to save the results to the local environment\n",
    "df['bert_embedding'] = df['text'].apply(preprocess_with_bert)\n",
    "\n",
    "# save the embeddings to the local environment\n",
    "joblib.dump(df['bert_embedding'].tolist(), 'bert_embeddings.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the embeddings from the local environment\n",
    "bert_embeddings = joblib.load('bert_embeddings.joblib')\n",
    "df['bert_embedding'] = bert_embeddings\n",
    "\n",
    "# extract the features and labels\n",
    "X = pd.DataFrame(df['bert_embedding'].to_list())\n",
    "y = df.iloc[:, 9:37].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform BERT embeddings to tensors(used in PyTorch)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "valid_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 100\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=768, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=28, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define the SimpleNN model\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, drop_prob=0.1):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]  # BERT embedding size\n",
    "hidden_dim = 64\n",
    "output_dim = y_train.shape[1]\n",
    "drop_prob = 0.25\n",
    "\n",
    "model = SimpleNN(input_dim, hidden_dim, output_dim, drop_prob).to(device)\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# calculate the accuracy\n",
    "def acc(pred, label):\n",
    "    pred = torch.round(pred)\n",
    "    correct = (pred == label).float()\n",
    "    acc = correct.sum() / correct.numel()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 0.1392, Val Loss: 0.1395\n",
      "Train Accuracy: 95.79%, Val Accuracy: 95.95%\n",
      "Validation loss decreased (inf --> 0.139521). Saving model ...\n",
      "Epoch 2\n",
      "Train Loss: 0.1283, Val Loss: 0.1353\n",
      "Train Accuracy: 95.95%, Val Accuracy: 95.98%\n",
      "Validation loss decreased (0.139521 --> 0.135252). Saving model ...\n",
      "Epoch 3\n",
      "Train Loss: 0.1263, Val Loss: 0.1362\n",
      "Train Accuracy: 95.97%, Val Accuracy: 95.99%\n",
      "Epoch 4\n",
      "Train Loss: 0.1251, Val Loss: 0.1332\n",
      "Train Accuracy: 95.99%, Val Accuracy: 96.00%\n",
      "Validation loss decreased (0.135252 --> 0.133200). Saving model ...\n",
      "Epoch 5\n",
      "Train Loss: 0.1244, Val Loss: 0.1350\n",
      "Train Accuracy: 96.00%, Val Accuracy: 96.00%\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "epochs = 5\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    train_acc = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(inputs)\n",
    "        \n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        accuracy = acc(output, labels)\n",
    "        train_acc += accuracy\n",
    "    \n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    val_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            output = model(inputs)\n",
    "            \n",
    "            val_loss = criterion(output, labels)\n",
    "            val_losses.append(val_loss.item())\n",
    "            \n",
    "            accuracy = acc(output, labels)\n",
    "            val_acc += accuracy\n",
    "    \n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    epoch_train_acc = train_acc / len(train_loader)\n",
    "    epoch_val_acc = val_acc / len(valid_loader)\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}')\n",
    "    print(f'Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}')\n",
    "    print(f'Train Accuracy: {epoch_train_acc * 100:.2f}%, Val Accuracy: {epoch_val_acc * 100:.2f}%')\n",
    "    \n",
    "    if epoch_val_loss <= valid_loss_min:\n",
    "        print(f'Validation loss decreased ({valid_loss_min:.6f} --> {epoch_val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        valid_loss_min = epoch_val_loss\n",
    "\n",
    "print('Training complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
